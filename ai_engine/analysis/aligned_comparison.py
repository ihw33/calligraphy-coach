#!/usr/bin/env python3
"""
ë¹¨ê°„ í…Œë‘ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë¹„êµ
ì‚¬ìš©ìê°€ ì¶”ê°€í•œ í…Œë‘ë¦¬ì™€ ê°€ì´ë“œì˜ í…Œë‘ë¦¬ë¥¼ ë§ì¶°ì„œ ì˜¤ë²„ë ˆì´
"""

import cv2
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os


def process_aligned_comparison():
    """í…Œë‘ë¦¬ ì •ë ¬ ë¹„êµ ì‹¤í–‰"""
    
    # ì´ë¯¸ì§€ ê²½ë¡œ
    reference_with_border = "/Users/m4_macbook/Desktop/ìŠ¤í¬ë¦°ìƒ· 2025-08-14 ì˜¤í›„ 12.42.19.png"  # êµë³¸ + ë¹¨ê°„ í…Œë‘ë¦¬
    guide_path = "/Users/m4_macbook/Desktop/ìŠ¤í¬ë¦°ìƒ· 2025-08-14 ì˜¤í›„ 12.42.53.png"  # ê²°êµ¬ ê°€ì´ë“œ
    user_path = "/Users/m4_macbook/Desktop/ìŠ¤í¬ë¦°ìƒ· 2025-08-14 ì˜¤í›„ 12.43.21.png"  # ì‚¬ìš©ì ê¸€ì
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    ref_img = cv2.imread(reference_with_border)
    guide_img = cv2.imread(guide_path)
    user_img = cv2.imread(user_path)
    
    if ref_img is None or guide_img is None or user_img is None:
        print("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("âœ… ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = "aligned_output"
    os.makedirs(output_dir, exist_ok=True)
    
    # í¬ê¸° í†µì¼ (ê°€ì´ë“œ í¬ê¸°ë¡œ)
    h, w = guide_img.shape[:2]
    ref_resized = cv2.resize(ref_img, (w, h))
    user_resized = cv2.resize(user_img, (w, h))
    
    # ë¹¨ê°„ í…Œë‘ë¦¬ ê²€ì¶œ
    ref_border = detect_red_border(ref_resized)
    guide_border = detect_red_border(guide_img)
    
    # í…Œë‘ë¦¬ ì •ë ¬
    aligned_ref = align_borders(ref_resized, ref_border, guide_border, guide_img.shape[:2])
    aligned_user = align_borders(user_resized, detect_red_border(user_resized), guide_border, guide_img.shape[:2])
    
    # ê¸€ì ì¶”ì¶œ
    ref_char = extract_character(aligned_ref)
    guide_char = extract_character(guide_img)
    user_char = extract_character(aligned_user)
    
    # ì˜¤ë²„ë ˆì´ ìƒì„±
    overlay1 = create_overlay(guide_img, aligned_ref, "êµë³¸")
    overlay2 = create_overlay(guide_img, aligned_user, "ì‚¬ìš©ì")
    overlay3 = create_triple_overlay(guide_img, ref_char, user_char)
    
    # ì ìˆ˜ ê³„ì‚°
    scores = calculate_scores(user_char, guide_char, ref_char)
    
    # ì‹œê°í™”
    visualize_results(
        ref_resized, user_resized, guide_img,
        aligned_ref, aligned_user,
        overlay1, overlay2, overlay3,
        scores, output_dir
    )
    
    return scores


def detect_red_border(img):
    """ë¹¨ê°„ìƒ‰ í…Œë‘ë¦¬ ê²€ì¶œ"""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    # ë¹¨ê°„ìƒ‰ ë²”ìœ„
    lower_red1 = np.array([0, 50, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([170, 50, 50])
    upper_red2 = np.array([180, 255, 255])
    
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = mask1 + mask2
    
    return red_mask


def align_borders(img, img_border, target_border, target_shape):
    """í…Œë‘ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬"""
    
    # í…Œë‘ë¦¬ ì»¨íˆ¬ì–´ ì°¾ê¸°
    img_contours, _ = cv2.findContours(img_border, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    target_contours, _ = cv2.findContours(target_border, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not img_contours or not target_contours:
        return img
    
    # ê°€ì¥ í° ì»¨íˆ¬ì–´ (í…Œë‘ë¦¬)
    img_rect = max(img_contours, key=cv2.contourArea)
    target_rect = max(target_contours, key=cv2.contourArea)
    
    # ë°”ìš´ë”© ë°•ìŠ¤
    ix, iy, iw, ih = cv2.boundingRect(img_rect)
    tx, ty, tw, th = cv2.boundingRect(target_rect)
    
    # ë³€í™˜ ê³„ì‚°
    scale_x = tw / iw if iw > 0 else 1
    scale_y = th / ih if ih > 0 else 1
    translate_x = tx - ix * scale_x
    translate_y = ty - iy * scale_y
    
    # ë³€í™˜ í–‰ë ¬
    M = np.array([[scale_x, 0, translate_x],
                  [0, scale_y, translate_y]], dtype=np.float32)
    
    # ì ìš©
    aligned = cv2.warpAffine(img, M, (target_shape[1], target_shape[0]),
                            borderValue=(255, 255, 255))
    
    return aligned


def extract_character(img):
    """ê¸€ì ì¶”ì¶œ (ë¹¨ê°„ í…Œë‘ë¦¬ ì œì™¸)"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
    
    # ë¹¨ê°„ìƒ‰ ì œê±°
    red_mask = detect_red_border(img)
    binary = cv2.bitwise_and(binary, cv2.bitwise_not(red_mask))
    
    return binary


def create_overlay(base_img, overlay_img, label):
    """ì˜¤ë²„ë ˆì´ ìƒì„±"""
    result = base_img.copy()
    
    # ê¸€ì ì¶”ì¶œ
    char_mask = extract_character(overlay_img)
    
    # ìƒ‰ìƒ ì„¤ì •
    if label == "êµë³¸":
        color = [0, 255, 0]  # ì´ˆë¡
        alpha = 0.3
    else:
        color = [255, 0, 0]  # íŒŒë‘
        alpha = 0.4
    
    # ì˜¤ë²„ë ˆì´
    mask = char_mask > 0
    color_overlay = np.zeros_like(result)
    color_overlay[:] = color
    result[mask] = cv2.addWeighted(result[mask], 1-alpha, color_overlay[mask], alpha, 0)
    
    return result


def create_triple_overlay(base_img, ref_char, user_char):
    """3ì¤‘ ì˜¤ë²„ë ˆì´ (ê°€ì´ë“œ + êµë³¸ + ì‚¬ìš©ì)"""
    result = base_img.copy()
    
    # êµë³¸: ì´ˆë¡
    ref_mask = ref_char > 0
    result[ref_mask, 1] = np.minimum(255, result[ref_mask, 1] + 100)
    
    # ì‚¬ìš©ì: íŒŒë‘
    user_mask = user_char > 0
    result[user_mask, 0] = np.minimum(255, result[user_mask, 0] + 100)
    
    # ê²¹ì¹˜ëŠ” ë¶€ë¶„: ë³´ë¼
    overlap = np.logical_and(ref_mask, user_mask)
    result[overlap] = [128, 0, 128]
    
    return result


def calculate_scores(user_char, guide_char, ref_char):
    """ì ìˆ˜ ê³„ì‚°"""
    scores = {}
    
    # 1. ê°€ì´ë“œì™€ì˜ ì¼ì¹˜ë„
    guide_overlap = np.logical_and(user_char > 0, guide_char > 0)
    guide_union = np.logical_or(user_char > 0, guide_char > 0)
    if np.sum(guide_union) > 0:
        scores['guide_match'] = (np.sum(guide_overlap) / np.sum(guide_union)) * 100
    else:
        scores['guide_match'] = 0
    
    # 2. êµë³¸ê³¼ì˜ ì¼ì¹˜ë„
    ref_overlap = np.logical_and(user_char > 0, ref_char > 0)
    ref_union = np.logical_or(user_char > 0, ref_char > 0)
    if np.sum(ref_union) > 0:
        scores['reference_match'] = (np.sum(ref_overlap) / np.sum(ref_union)) * 100
    else:
        scores['reference_match'] = 0
    
    # 3. ì¤‘ì‹¬ ì •ë ¬
    M_user = cv2.moments(user_char)
    M_guide = cv2.moments(guide_char)
    
    if M_user["m00"] > 0 and M_guide["m00"] > 0:
        cx_user = int(M_user["m10"] / M_user["m00"])
        cy_user = int(M_user["m01"] / M_user["m00"])
        cx_guide = int(M_guide["m10"] / M_guide["m00"])
        cy_guide = int(M_guide["m01"] / M_guide["m00"])
        
        h, w = user_char.shape
        max_dist = np.sqrt(w**2 + h**2)
        actual_dist = np.sqrt((cx_user - cx_guide)**2 + (cy_user - cy_guide)**2)
        scores['center_alignment'] = max(0, 100 * (1 - actual_dist / max_dist))
    else:
        scores['center_alignment'] = 0
    
    # 4. í¬ê¸° ì¼ì¹˜ë„
    user_area = np.sum(user_char > 0)
    guide_area = np.sum(guide_char > 0)
    if guide_area > 0:
        scores['size_match'] = min(user_area, guide_area) / max(user_area, guide_area) * 100
    else:
        scores['size_match'] = 0
    
    # 5. íš êµ¬ì¡°
    user_edges = cv2.Canny(user_char.astype(np.uint8), 50, 150)
    guide_edges = cv2.Canny(guide_char.astype(np.uint8), 50, 150)
    
    edge_match = np.logical_and(user_edges > 0, guide_edges > 0)
    if np.sum(guide_edges > 0) > 0:
        scores['stroke_structure'] = (np.sum(edge_match) / np.sum(guide_edges > 0)) * 100
    else:
        scores['stroke_structure'] = 0
    
    # ìµœì¢… ì ìˆ˜
    scores['final_score'] = np.mean([
        scores['guide_match'],
        scores['reference_match'],
        scores['center_alignment'],
        scores['size_match'],
        scores['stroke_structure']
    ])
    
    return scores


def visualize_results(ref_img, user_img, guide_img,
                      aligned_ref, aligned_user,
                      overlay1, overlay2, overlay3,
                      scores, output_dir):
    """ê²°ê³¼ ì‹œê°í™”"""
    
    fig = plt.figure(figsize=(18, 10))
    
    # ì›ë³¸ ì´ë¯¸ì§€
    ax1 = plt.subplot(2, 4, 1)
    ax1.imshow(cv2.cvtColor(ref_img, cv2.COLOR_BGR2RGB))
    ax1.set_title('êµë³¸ (ë¹¨ê°„ í…Œë‘ë¦¬)', fontsize=11)
    ax1.axis('off')
    
    ax2 = plt.subplot(2, 4, 2)
    ax2.imshow(cv2.cvtColor(user_img, cv2.COLOR_BGR2RGB))
    ax2.set_title('ì‚¬ìš©ì ê¸€ì', fontsize=11)
    ax2.axis('off')
    
    ax3 = plt.subplot(2, 4, 3)
    ax3.imshow(cv2.cvtColor(guide_img, cv2.COLOR_BGR2RGB))
    ax3.set_title('ê²°êµ¬ ê°€ì´ë“œ', fontsize=11)
    ax3.axis('off')
    
    # ì˜¤ë²„ë ˆì´
    ax4 = plt.subplot(2, 4, 5)
    ax4.imshow(cv2.cvtColor(overlay1, cv2.COLOR_BGR2RGB))
    ax4.set_title('êµë³¸ + ê°€ì´ë“œ (ì´ˆë¡)', fontsize=11)
    ax4.axis('off')
    
    ax5 = plt.subplot(2, 4, 6)
    ax5.imshow(cv2.cvtColor(overlay2, cv2.COLOR_BGR2RGB))
    ax5.set_title('ì‚¬ìš©ì + ê°€ì´ë“œ (íŒŒë‘)', fontsize=11)
    ax5.axis('off')
    
    ax6 = plt.subplot(2, 4, 7)
    ax6.imshow(cv2.cvtColor(overlay3, cv2.COLOR_BGR2RGB))
    ax6.set_title('ì „ì²´ ì˜¤ë²„ë ˆì´\n(ì´ˆë¡:êµë³¸, íŒŒë‘:ì‚¬ìš©ì, ë³´ë¼:ê²¹ì¹¨)', fontsize=11)
    ax6.axis('off')
    
    # ì ìˆ˜
    ax7 = plt.subplot(2, 4, 4)
    
    score_text = f"""
ğŸ“Š í…Œë‘ë¦¬ ì •ë ¬ ë¶„ì„ ê²°ê³¼

ê°€ì´ë“œ ì¼ì¹˜ë„: {scores['guide_match']:.1f}%
êµë³¸ ì¼ì¹˜ë„: {scores['reference_match']:.1f}%
ì¤‘ì‹¬ ì •ë ¬: {scores['center_alignment']:.1f}%
í¬ê¸° ì¼ì¹˜: {scores['size_match']:.1f}%
íš êµ¬ì¡°: {scores['stroke_structure']:.1f}%

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ìµœì¢… ì ìˆ˜: {scores['final_score']:.1f}ì 
    """
    
    ax7.text(0.1, 0.5, score_text, fontsize=11,
            verticalalignment='center', fontfamily='monospace')
    ax7.axis('off')
    
    # í‰ê°€
    ax8 = plt.subplot(2, 4, 8)
    
    final = scores['final_score']
    if final >= 80:
        grade = "A"
        msg = "ğŸ‰ í›Œë¥­í•©ë‹ˆë‹¤!"
        color = 'green'
    elif final >= 70:
        grade = "B"
        msg = "ğŸ‘ ì˜í–ˆìŠµë‹ˆë‹¤!"
        color = 'blue'
    elif final >= 60:
        grade = "C"
        msg = "ğŸ’¡ ì–‘í˜¸í•©ë‹ˆë‹¤"
        color = 'orange'
    else:
        grade = "D"
        msg = "ğŸ“š ì—°ìŠµ í•„ìš”"
        color = 'red'
    
    ax8.text(0.5, 0.6, grade, fontsize=48, fontweight='bold',
            ha='center', va='center', color=color)
    ax8.text(0.5, 0.3, msg, fontsize=14,
            ha='center', va='center')
    ax8.text(0.5, 0.1, f"{final:.1f}ì ", fontsize=12,
            ha='center', va='center')
    ax8.set_xlim(0, 1)
    ax8.set_ylim(0, 1)
    ax8.axis('off')
    
    plt.suptitle('í…Œë‘ë¦¬ ì •ë ¬ ê¸°ì¤€ ê¸€ì ë¹„êµ ë¶„ì„', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    # ì €ì¥
    result_path = os.path.join(output_dir, 'aligned_analysis.png')
    plt.savefig(result_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    # ì˜¤ë²„ë ˆì´ ì €ì¥
    cv2.imwrite(os.path.join(output_dir, 'overlay_reference.png'), overlay1)
    cv2.imwrite(os.path.join(output_dir, 'overlay_user.png'), overlay2)
    cv2.imwrite(os.path.join(output_dir, 'overlay_all.png'), overlay3)
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}/")


def main():
    print("="*60)
    print("ğŸ“ í…Œë‘ë¦¬ ì •ë ¬ ë¹„êµ ë¶„ì„")
    print("="*60)
    
    scores = process_aligned_comparison()
    
    if scores:
        print("\n" + "="*60)
        print("ğŸ“Š ìµœì¢… ê²°ê³¼")
        print("="*60)
        print(f"ê°€ì´ë“œ ì¼ì¹˜ë„: {scores['guide_match']:.1f}%")
        print(f"êµë³¸ ì¼ì¹˜ë„: {scores['reference_match']:.1f}%")
        print(f"ì¤‘ì‹¬ ì •ë ¬: {scores['center_alignment']:.1f}%")
        print(f"í¬ê¸° ì¼ì¹˜: {scores['size_match']:.1f}%")
        print(f"íš êµ¬ì¡°: {scores['stroke_structure']:.1f}%")
        print("-"*60)
        print(f"ğŸ¯ ìµœì¢… ì ìˆ˜: {scores['final_score']:.1f}ì ")
        print("="*60)


if __name__ == "__main__":
    main()